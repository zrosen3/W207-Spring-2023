{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHLcriKWLRe4"
   },
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nNOD-Z7SzAq"
   },
   "source": [
    "## Data as matrices\n",
    "Data usually comes in the form of matrices. The Python Numpy library makes it easy to manipulate matrices efficiently. See the [Numpy Tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWlmuAMwTZ3P"
   },
   "outputs": [],
   "source": [
    "# Print these to make sure you understand what is being generated.\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.arange(1, 13).reshape(3, 4)\n",
    "C = np.ones((2, 3))\n",
    "D = np.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4wvvzKoUIAN"
   },
   "source": [
    "---\n",
    "### Exercise 1: Matrix manipulation (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following computations using numpy functions and print the results. Note that the `*` operator implies matrix multiplication -- make sure the dimensions align!\n",
    "1. 2A + 1\n",
    "2. Sum the rows of B\n",
    "3. Sum the columns of B\n",
    "4. Number of elements of B greater than 5\n",
    "5. C + C\n",
    "6. A * B\n",
    "7. (B * B) - D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJtwrjdO6TbS"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbCRG2-uUKCT"
   },
   "source": [
    "## Data for Supervised Learning\n",
    "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
    "\n",
    "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ulmn_bFdU87t"
   },
   "outputs": [],
   "source": [
    "def create_1d_data(num_examples=10, w=2, b=1, random_scale=1):\n",
    "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
    "\n",
    "  Args:\n",
    "    num_examples: number of examples to generate\n",
    "    w: desired slope\n",
    "    b: desired intercept\n",
    "    random_scale: add uniform noise between -random_scale and +random_scale\n",
    "\n",
    "  Returns:\n",
    "    X and Y with shape (num_examples)\n",
    "  \"\"\"\n",
    "  X = np.arange(num_examples)\n",
    "  np.random.seed(4)  # consistent random number generation\n",
    "  deltas = np.random.uniform(low=-random_scale, high=random_scale, size=X.shape)\n",
    "  Y = b + deltas + w * X\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qJg0IiYVJ8U"
   },
   "outputs": [],
   "source": [
    "# Create some artificial data using create_1d_data.\n",
    "X, Y = create_1d_data()\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6coKbXSpXOz"
   },
   "source": [
    "---\n",
    "### Exercise 2: Models for Data (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
    "\n",
    "Let's consider two possible models for this data:\n",
    "1. $M_1(x) = x+5$ \n",
    "2. $M_2(x) = 2x+1$\n",
    "\n",
    "Compute the predictions of models $M_1$ and $M_2$ for the values in $X$. These predictions should be vectors of the same shape as $Y$. Then plot the prediction lines of these two models overlayed on the \"observed\" data $(X, Y)$. Use [plt.plot()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) to draw the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHIY5kNXUIAP"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH-0soZiWx9x"
   },
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
    "\n",
    "\\begin{equation}\n",
    "\\textit{MSE} = \\frac{1}{|Y|} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AyY2DpxYLI0"
   },
   "source": [
    "---\n",
    "### Exercise 3: Computing MSE (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function for computing the MSE metric and use it to compute the MSE for the two models above, $M_1$ and $M_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCeAfI5mW9sg"
   },
   "outputs": [],
   "source": [
    "def MSE(true_values, predicted_values):\n",
    "  \"\"\"Return the MSE between true_values and predicted values.\"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uF-x9DI2ZOKq"
   },
   "outputs": [],
   "source": [
    "print ('MSE for M1:', MSE(Y, M1))\n",
    "print ('MSE for M2:', MSE(Y, M2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDiy3OZwZlwj"
   },
   "source": [
    "## Generalization\n",
    "\n",
    "Our data $(X, Y)$ represents just a sample of all possible input-output pairs we might care about. A model will be useful to the extent we can apply it to new inputs. Consider the more complex model below, which appears to produce a much smaller mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns1siZ9DZvSY"
   },
   "outputs": [],
   "source": [
    "# Fit an 8-th degree polynomial to (X, Y). See np.polyfit for details.\n",
    "polynomial_model_coefficients = np.polyfit(X, Y, deg=8)\n",
    "polynomial_model = np.poly1d(polynomial_model_coefficients)\n",
    "M3 = polynomial_model(X)\n",
    "fig = plt.scatter(X, Y)\n",
    "plt.plot(X, M3, '-k')\n",
    "print ('MSE for M3:', MSE(Y, M3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2m9YmLMZ1EV"
   },
   "source": [
    "---\n",
    "### Exercise 4: Generalization (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain whether you expect $M_3$ to be better than $M_2$ at predicting the labels for new unseen inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0Zpx79_aQEC"
   },
   "source": [
    "*Writen answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9EH9D7Faf9n"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hIdZHngdrET"
   },
   "source": [
    "## Review\n",
    "\n",
    "* In **Supervised Machine Learning**, we must start with data in the form $(X,Y)$ where $X$ are the inputs and $Y$ are the output labels.\n",
    "* A **model** is a function that maps an input $x$ to an output $y$. The model's output is referred to as a **prediction**, denoted by $\\hat{y}$.\n",
    "* We **evaluate** predictions by comparing them to the true labels. This measurement is called a **loss** or **error**. For real-valued data, **mean squared error** is a common metric.\n",
    "* A model is only as good as its ability to **generalize** to new examples."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "copyright",
    "xxOhpvdW6TbX",
    "exercise-1-key-1",
    "43ZTSJEc526U",
    "exercise-5-key-1",
    "ubHispCAA_5u",
    "exercise-6-key-1",
    "5p1IvWjfEjqm",
    "exercise-9-key-1"
   ],
   "name": "01 Introduction.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
